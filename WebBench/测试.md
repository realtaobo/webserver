<!--
 * @Autor: taobo
 * @Date: 2020-06-02 12:36:22
 * @LastEditTime: 2020-06-02 13:58:48
 * @Description: file content
--> 
### 测试环境
* OS：Centos 7
* 内存：1G
* CPU：i5-8250U

### 测试方法
* 选择本地测试方法，使用虚拟机跑起进程
* 使用工具Webbench，开启1000客户端进程，时间为60s
* 分别测试IO线程数目对实际工作环境的影响
* 关闭所有的输出及Log
* 测试响应为内存中的简单HTTP报头
* 线程池分别开启4/10/20/30/40线程
* 关闭Nagle算法，TCP默认是开启的
### 测试结果
`webbench -c1000 -t60 http://127.0.0.1/`
|线程池 | 4| 10|20|30|40|
| - | :-: | -: | -: | -: | -: | 
|susceed|11222|12385| 10132|9368| 8490| 
|failed|0|0|0|0|0|

* 可以发现在高并发的场景之下，线程池数目的不合理设计会影响服务器的响应能力，最佳设置数目应该限定为cpu核数+1附近，显然由上面的数据可以看出基本符合
* 在基于C++11重新编写该Server时为提高开发效率对于缓冲区直接使用了std::string，未使用自定义(基于C风格字符串)缓冲区，这在一定程度上会降低效率。
* 一个改进是针对listen_fd,在[历史版本](https://github.com/tryturned/HttpServer)中虽然也使用epoll的边沿触发模式，但每次主线程被唤醒之后仅accept一次，在高并发的情况下显然效率太低，此处借助while循环以提升效率。
* 测试发现空闲时，Server几乎不占CPU负载，处理时，主线程负载也较小。
### 测试结果截图
* 线程池数目为4时压测：  
![bench4](https://gitee.com/windyGOlife/webserver/raw/master/example/bench4.png)  
* 线程池数目为4时空闲负载：  
![top4_spare](https://gitee.com/windyGOlife/webserver/raw/master/example/top4_spare.png)
* 线程池数目为4时主线程负载：  
![top4_full](https://gitee.com/windyGOlife/webserver/raw/master/example/top4_full.png) 

* 线程池数目为10时压测： 
![bench10](https://gitee.com/windyGOlife/webserver/raw/master/example/bench10.png)  
* 线程池数目为20时压测：    
![bench20](https://gitee.com/windyGOlife/webserver/raw/master/example/bench20.png)  
* 线程池数目为30时压测：  
![bench30](https://gitee.com/windyGOlife/webserver/raw/master/example/bench30.png)  
* 线程池数目为40时压测：  
![bench40](https://gitee.com/windyGOlife/webserver/raw/master/example/bench40.png)